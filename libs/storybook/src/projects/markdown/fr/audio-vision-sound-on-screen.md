\---  
description: "Audio-Vision : Méthodologie du son à l'écran"  
pubDate"Apr 5, 2022"   
heroImage"e9708192-8123-461e-9214-4d4e9864aee5_1691773573.webp?auto=compress,format"   
author"Syntia"   
categories"projets, études sonores, audiovision"   
subcategories"médias audiovisuels, classification sonore, médias interdisciplinaires, gouvernance sonore, écoute active"   
\---  

[https://player.vimeo.com/video/386757761?h=c549f73bae&dnt=1&app\_id=122963](https://player.vimeo.com/video/386757761?h=c549f73bae&dnt=1&app_id=122963)

Christine Groult - 23 novembre 2019, [https://issueprojectroom.org/video/christine-groult](https://issueprojectroom.org/video/christine-groult)

L'objectif de l'œuvre phare de Michel Chion, "Audio-Vision : le son à l'écran", a exercé une influence significative sur notre compréhension des relations entre le son et l'image depuis sa première publication en 1993. Il s'agit de démontrer la réalité de la combinaison audiovisuelle, à savoir qu'une perception influence l'autre et la transforme. Nous ne voyons jamais la même chose lorsque nous entendons également ; nous n'entendons pas la même chose lorsque nous voyons également. Nous devons donc aller au-delà des préoccupations telles que l'identification de prétendue redondance entre les deux domaines et le débat sur les interrelations entre les forces (la célèbre question posée dans les années 1970 : "Qu'est-ce qui est le plus important, le son ou l'image ?").

Ce travail est à la fois théorique et pratique. Tout d'abord, il décrit et formule la relation audiovisuelle comme un contrat, c'est-à-dire l'opposé d'une relation naturelle découlant d'une sorte d'harmonie préexistante entre les perceptions.

La perception visuelle et auditive sont de natures beaucoup plus disparates qu'on ne pourrait le penser. La raison pour laquelle nous en sommes à peine conscients est que ces deux perceptions s'influencent mutuellement dans le contrat audiovisuel, se prêtant mutuellement leurs propriétés respectives par la contamination et la projection.

"le son fixe" est celui qui n'entraîne aucune variation lorsqu'il est entendu. Cette caractéristique se trouve uniquement dans certains sons d'origine artificielle : le son d'une tonalité de téléphone, ou le bourdonnement d'un haut-parleur. Les torrents et les cascades peuvent également produire un grondement proche du bruit blanc, mais il est rare de ne pas entendre au moins une trace d'irrégularité et de mouvement. En tant que trace d'un mouvement ou d'une trajectoire, le son a donc sa propre dynamique temporelle.

La perception du son et la perception visuelle ont leur propre rythme moyen, où l'oreille analyse, traite et synthétise plus rapidement que l'œil, mais ce n'est pas une question d'attention. Pour les personnes entendants, le son est le véhicule du langage, et une phrase parlée fait travailler l'oreille très rapidement ; en comparaison, lire avec les yeux est notablement plus lent, sauf dans des cas spécifiques de formation particulière, comme pour les personnes sourdes. L'œil perçoit plus lentement parce qu'il doit explorer dans l'espace tout en suivant dans le temps. L'oreille isole un détail de son champ auditif et suit ce point ou cette ligne dans le temps. Lors du premier contact avec un message audiovisuel, l'œil est plus habile spatialement, et l'oreille plus habile temporellement.

#### **Le seuil temporel de l'oreille**

De plus, nous devons corriger la formulation selon laquelle l'audition se produit en continu. L'oreille écoute en réalité par de brefs fragments, et ce qu'elle perçoit et mémorise consiste déjà en de courtes synthèses de deux ou trois secondes du son tel qu'il évolue. Cependant, au sein de ces deux ou trois secondes, perçues comme une gestalt, l'oreille, ou plutôt le système oreille-cerveau, a minutieusement et sérieusement effectué son enquête de manière à ce que son rapport global de l'événement, livré périodiquement, soit bourré de données précises et spécifiques qui ont été recueillies.

Il en résulte un paradoxe : nous n'entendons pas les sons, au sens de les reconnaître, avant un court moment après les avoir perçus.

Claquez vos mains bruyamment et écoutez le son qui en résulte. L'audition, c'est-à-dire la perception synthétisée d'un petit fragment de l'événement auditif, consigné dans la mémoire, suivra très étroitement l'événement, elle ne sera pas totalement simultanée avec lui.

#### **Les trois modes d'écoute**

Lorsque nous demandons à quelqu'un de parler de ce qu'il a entendu, ses réponses sont frappantes en raison de l'hétérogénéité des niveaux d'écoute auxquels elles se réfèrent. Cela s'explique par le fait qu'il existe au moins trois modes d'écoute, chacun d'entre eux traitant d'objets différents. Nous les appellerons écoute causale, écoute sémantique et écoute réduite.

##### **Écoute causale**

L'écoute causale, la plus courante, consiste à écouter un son afin de recueillir des informations sur sa cause (ou sa source). Lorsque nous ne pouvons pas voir la cause du son, le son peut constituer notre principale source d'information à son sujet. Une cause invisible pourrait être identifiée par des connaissances ou une prévision logique ; l'écoute causale (qui ne s'éloigne que rarement de zéro) peut élaborer sur ces connaissances.

Dans certains cas, nous pouvons reconnaître la cause précise : la voix d'une personne spécifique, le son produit par un objet particulier unique. Mais nous reconnaissons rarement une source unique exclusivement sur la base du son que nous entendons hors contexte. Même si les chiens semblent capables d'identifier la

 voix de leur maître parmi des centaines de voix, il est très douteux que le maître, les yeux fermés et sans autre information, puisse également discerner la voix de son propre chien.

##### **Écoute sémantique**

J'appelle écoute sémantique ce qui se réfère à un code ou à une langue pour interpréter un message : la langue parlée, bien sûr, ainsi que le code Morse et d'autres codes similaires.

De toute évidence, on peut écouter une seule séquence sonore en employant à la fois les modes causal et sémantique. Nous entendons à la fois ce que quelqu'un dit et comment il le dit. En un sens, écouter de manière causale une voix, c'est écouter de manière sémantique sa perception de l'écriture ou du code d'un texte écrit.

##### **Écoute réduite**

Pierre Schaeffer a donné le nom d'écoute réduite au mode d'écoute qui se concentre sur les caractéristiques du son lui-même, indépendamment de sa cause et de sa signification.

L'écoute réduite prend le son - verbal, joué sur un instrument, bruits, ou autre - comme l'objet à observer en lui-même plutôt que comme un véhicule pour autre chose.

Une séance d'écoute réduite est une expérience très instructive. Les participants réalisent rapidement qu'en parlant des sons, ils passent constamment entre le contenu réel du son, sa source et sa signification. Une forme de repli entraîne un relativisme subjectif total. Chaque individu entend quelque chose de différent, et le son perçu reste à jamais inconnu. Mais la perception n'est pas un phénomène purement individuel, car elle participe à une forme particulière d'objectivité, celle des perceptions partagées. Et c'est dans cette objectivité née de l'intersubjectivité que l'écoute réduite, telle que l'a définie Schaeffer, devrait être située.

En écoute réduite, l'inventaire descriptif d'un son ne peut pas être compilé en une seule écoute. Il faut écouter plusieurs fois, et c'est pourquoi le son doit être fixé, enregistré. Cela a l'énorme avantage d'ouvrir nos oreilles et d'aiguiser notre capacité d'écoute.

Lorsque nous identifions la hauteur d'une note ou comprenons un intervalle entre deux notes, nous pratiquons l'écoute réduite ; car la hauteur est une caractéristique inhérente du son, indépendante de la cause du son ou de la compréhension de sa signification.

Ce qui complique les choses, c'est qu'un son n'est pas défini uniquement par sa hauteur ; il possède de nombreuses autres caractéristiques perceptuelles.

Peut-on formuler un système descriptif des sons, indépendamment de toute considération de leur cause ? Schaeffer a montré que cela était possible, mais il n'a réussi qu'à délimiter le territoire, en proposant, dans son "Traité des objets musicaux", un système de classification. Ce système n'est certainement ni complet ni à l'abri de la critique, mais il a le grand mérite d'exister.

#### **Sons acousmatiques**

Acousmatique, un mot d'origine grecque découvert par Jerome Peignot et théorisé par Pierre Schaeffer, décrit "les sons que l'on entend sans voir leur cause d'origine". La radio, le phonographe et le téléphone, tous des médias acousmatiques par définition, transmettent les sons sans montrer leur émetteur. Le terme "musique acousmatique" a également été inventé ; par exemple, le compositeur Francis Bayle l'utilise pour désigner la musique de concert créée pour un support enregistré, éliminant délibérément la possibilité de voir les causes initiales des sons.

Que peut-on appeler l'opposé du son acousmatique ? Schaeffer a proposé le terme "direct", mais comme ce mot prête à tant d'ambiguïtés, nous allons inventer le terme "son visualisé" - c'est-à-dire accompagné de la vue de sa source ou de sa cause. Dans un film, un son hors champ est acousmatique.

##### **Son hors champ**

Le son hors champ passif est un son qui crée une atmosphère qui enveloppe et stabilise l'image, sans nous inciter de quelque manière que ce soit à regarder ailleurs ou à anticiper de voir sa source. L'espace hors champ passif ne contribue pas à la dynamique du montage et de la construction des scènes - au contraire, il offre à l'oreille un endroit stable (le mélange général des sons d'une ville), ce qui permet au montage de se déplacer encore plus librement dans l'espace, d'inclure plus de plans rapprochés, et ainsi de suite, sans désorienter le spectateur dans l'espace. Les sons principaux dans l'espace hors champ passif sont les sons du territoire et les éléments de l'environnement sonore.

En 1954, "Fenêtre sur cour" comprenait beaucoup de sons hors champ passifs : les bruits de la ville, les sons de la cour de l'appartement, et la radio, qui, pleine de réverbération, orientait l'oreille vers le cadre contextuel de la scène sans soulever de questions ni appeler à la visualisation de leurs sources.

##### **Les déchets hors champ**

Les déchets hors champ sont un cas particulier de l'espace hors champ passif qui résulte d'un son multicanal. Ils sont créés lorsque les haut-parleurs hors champ "collectent" des bruits - sifflements, chocs, explosions, crashs - qui sont le produit d'une catastrophe ou d'une chute au centre de l'image. Les films d'action et de cascades ont souvent recours à cet effet. Parfois poétique, parfois intentionnellement comique, les "déchets hors champ" donnent momentanément une existence presque physique à des objets au moment même où ils meurent.

#### **Fidélité sonore**

Mais lorsque nous disons avec déception que "le son et l'image ne vont pas bien ensemble", nous devrions parfois l'attribuer exclusivement à la qualité médiocre de la production.

Quelqu'un qui écoute un orchestre sur un système sonore dans son salon ne sera probablement pas en mesure de le comparer à un orchestre jouant devant chez lui. Il convient de savoir, en fait, que la

 notion de haute fidélité est purement commerciale et ne correspond à rien de précis ou de vérifiable.

Pensez aux livres pour enfants qui enseignent les bruits que font les animaux : comme s'il existait la moindre connexion, en dehors de la connexion créée par un entraînement purement pavlovien, entre le son qu'un canard fait et son apparence, ou les mots onomatopéiques pour l'appel du canard dans différentes langues.

#### **Le rôle du son**

Le son multiprésent d'aujourd'hui a insidieusement privé l'image de certaines fonctions - par exemple, la fonction de structuration de l'espace. Mais bien que le son ait modifié la nature de l'image, il n'a pas touché à la centralité de l'image en tant qu'élément qui attire l'attention. L'évolution "quantitative" du son - en quantité d'amplification, d'information et de nombre de pistes simultanées - n'a pas ébranlé l'image de son piédestal. Le son a toujours le rôle de nous montrer ce qu'il veut que nous voyions dans l'image. À partir de cette image, nous ne pouvons voir qu'un côté des choses, qu'à moitié, toujours changeant.

Pourtant, il n'y a qu'un élément que le cinéma n'a pas réussi à traiter de cette manière, un élément qui reste contraint à la clarté et à la stabilité perpétuelles, et c'est le dialogue.

##### **Analyse narrative**

Une comparaison entre le son et l'image est également nécessaire au niveau de la narration et de la figuration. Pour ce faire, nous pourrions commencer par poser les questions suivantes : Que j'entends de ce que je vois ? et Que je vois de ce que j'entends ? Lorsque la projection sur l'image ainsi que le son ne sont pas explicitement montrés, encore moins nommés, laissant l'impression de points de synchronisation, car le spectateur ne peut s'empêcher de remarquer la discontinuité et le contexte de non-formes.

Réf : "Audio-Vision : Le son à l'écran" de Michel Chion