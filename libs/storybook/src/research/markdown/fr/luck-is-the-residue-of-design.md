# La chance est le résidu du dessein

La chance est le résidu du dessein et est régie par des causes qui sont
généralement en notre pouvoir de gouverner.

Tout comme dans les tensions entre regarder et sauter, explorer et exploiter,
l'un des compromis les plus centraux en informatique est entre le tri et la
recherche. Le principe de base est de trier les matériaux comme un coup porté
contre l'effort de les rechercher plus tard. Penser au tri comme étant précieux
seulement pour soutenir l'avenir nous dit quelque chose de surprenant :

Trier quelque chose que vous ne rechercherez jamais est un pur gaspillage ;
rechercher quelque chose que vous n'avez jamais trié est simplement inefficace.

Par exemple, sur les moteurs de recherche, le tri des informations est effectué
à l'avance avant que les résultats ne soient disponibles, et la recherche est
effectuée par des utilisateurs pour qui le temps est essentiel. Tous ces
facteurs plaident en faveur d'un tri préalable considérable, ce que font en
effet les moteurs de recherche.

Le traitement de l'information a commencé aux États-Unis lors des recensements
du XIXe siècle, avec le développement, par Herman Hollerith et plus tard IBM, de
dispositifs de tri de cartes perforées physiques. En 1936, IBM a commencé à
produire une série de machines appelées « collateurs » qui pouvaient fusionner
deux piles de cartes ordonnées séparément en une seule. Tant que les deux piles
étaient elles-mêmes triées, la procédure de fusion en une seule pile triée était
incroyablement simple : il suffisait de comparer les deux cartes du dessus entre
elles, de déplacer la plus petite dans la nouvelle pile que vous créez, et de
répéter jusqu'à la fin.

En fait, c'est en grande partie le tri qui a donné naissance à l'ordinateur.
L'informatique nous donne un moyen de comprendre ce qui se passe en coulisse
dans tous ces cas, ce qui à son tour peut nous offrir un aperçu pour ces moments
où nous sommes celui qui doit organiser des factures, des papiers, des livres,
des chaussettes et probablement plus de fois chaque jour que nous le réalisons.
En quantifiant le vice (et la vertu) du monde qui nous entoure, elle nous montre
également les cas où il ne fait en fait pas sens de créer un ordre du tout.

En réaction à des turbulences économiques massives, le président Franklin D.
Roosevelt a développé l'idée d'une Administration de la Sécurité Sociale (SSA),
un filet de sécurité pour aider ceux qui manquent de protection financière — les
personnes âgées, les personnes handicapées, les chômeurs, et les veuves et
orphelins. Lorsqu'il a signé la législation en août 1935, le document était peu
fourni en détails administratifs. Le défi de créer et de gérer plus de 27
millions de comptes individuels restait à relever. C'était une tâche
herculéenne. Le système devait collecter une quantité massive de données
salariales, calculer les paiements et transmettre les informations au
Département du Trésor des États-Unis, qui émettrait des chèques pour les
bénéficiaires qualifiés. Le plus grand travail de comptabilité de l'histoire à
l'époque était également confronté à un calendrier redoutable. La loi dictait
qu'elle soit en place d'ici le 1er janvier 1937.

Peu de temps avant tout cela, au début des années de la Dépression, Thomas J.
Watson Sr., le président d'IBM, a fait un pari risqué. Convaincu que le projet
de loi sur la SSA finirait par être adopté, il envisageait une énorme
opportunité commerciale pour toute entreprise capable de répondre au besoin
accru de gestion des données dans un gouvernement élargi.

Une fois que le Congrès a formellement approuvé le programme de sécurité
sociale, le gouvernement a choisi IBM parmi de nombreux soumissionnaires,
achetant toutes les machines en stock et en commandant beaucoup d'autres. La
machine comptable IBM 405 et le Collateur 077 se sont révélés être les
calculateurs les plus avancés disponibles à l'époque, les premiers à traiter
l'information de manière alphanumérique, en traduisant l'information binaire en
lettres en reconnaissant des motifs spécifiques de uns et de zéros. Lorsqu'elle
a été dévoilée en 1934, en tabulant 150 cartes par minute, la 405 représentait
la pointe de la technologie de traitement des données.

Le programme que John von Neumann a écrit en 1945 pour démontrer la puissance de
l'ordinateur à programme enregistré a poussé l'idée de la collation à son
ultime. Trier deux cartes est simple : il suffit de mettre la plus petite en
haut. Et étant donné une paire de piles de deux cartes, toutes deux triées, vous
pouvez facilement les collationner en une pile ordonnée de quatre. Répéter cette
astuce quelques fois, vous construiriez des piles plus grandes, chacune d'elles
déjà triée. Assez rapidement, vous pourriez vous collationner un jeu complet
parfaitement trié.

Lorsqu'il est temps de s'organiser, vous avez deux options. D'abord, vous devez
décider quoi garder, puis comment l'arranger. L'aperçu fondamental — que les
fichiers demandés doivent être stockés près de l'endroit où ils sont utilisés —
se traduit également dans des environnements purement physiques. Par exemple,
les énormes centres de distribution d'Amazon renoncent généralement à tout type
d'organisation compréhensible par l'homme. Leur brevet concerne l'expédition
d'articles récemment populaires dans une région donnée vers un entrepôt de mise
en scène dans cette région, comme avoir leur propre CDN pour les biens
physiques.

On nous dit que nos données sont « dans le nuage », ce qui est censé suggérer un
lieu diffus, lointain. Encore une fois, aucune de ces affirmations n'est vraie.
La réalité est que l'Internet concerne tout un ensemble de fils physiques et de
racks métalliques. Et c'est beaucoup plus lié à la géographie que vous pourriez
l'imaginer.

Si vous pouvez créer un cache de contenu de page Web qui est physiquement,
géographiquement plus proche des personnes qui le désirent, vous pouvez servir
ces pages plus rapidement. Une grande partie du trafic sur l'internet est
désormais gérée par des « réseaux de distribution de contenu » (CDN), qui
disposent d'ordinateurs dans le monde entier qui maintiennent des copies de
sites Web populaires. Cela permet aux utilisateurs demandant ces pages d'obtenir
leurs données d'un ordinateur proche, sans avoir à faire un long trajet à
travers les continents jusqu'au serveur d'origine.

Une grande partie de votre temps à utiliser un navigateur moderne est consacrée
à l'équivalent numérique de la manipulation de papiers. Cette manipulation est
également exactement reflétée sur les interfaces de changement de tâche de
Windows et de Mac OS, listant vos applications dans l'ordre de la plus récemment
à la moins récemment utilisée.

La mise en cache des onglets actifs du navigateur fonctionne de manière
similaire. D'abord, lorsqu'on décide quoi garder et quoi jeter, le principe du
Dernièrement Utilisé (LRU) est le plus courant. LRU est ce que les scientifiques
appellent la « localité temporelle » : si un programme a demandé une information
particulière une fois, il est probable qu'il le fasse à nouveau dans un avenir
proche. Cela résulte en partie de la manière dont les ordinateurs résolvent les
problèmes (par exemple, en exécutant une boucle qui effectue des séries rapides
de lectures et d'écritures), mais cela émerge également de la manière dont les
gens résolvent les problèmes.

Le parallèle direct entre trouver le meilleur algorithme qui anticiperait et
exécuterait une politique optimale est la « clairvoyance » — c'est qu'il y a un
potentiel pour appliquer consciemment les solutions à vos plus gros problèmes en
reconnaissant la science qui se cache derrière. Généralement, il y a des cas où
un système sait à quoi s'attendre lorsque vous vous en approchez aussi
intuitivement que possible.

Par exemple, LRU nous enseigne que la prochaine chose à laquelle nous pouvons
nous attendre est la dernière dont nous avons besoin, tandis que la chose dont
nous aurons besoin après cela est la deux

ième la plus récente. Hier, j'ai créé un rapport sur les métriques d'intégration
continue et de livraison, et en cherchant combien de temps les ingénieurs
passent à attendre chaque workflow de déploiement sur une base quotidienne, j'ai
constaté que le système construit de manière bien organisée et complète n'est
pas toujours stable et coûteux ou efficace en termes de temps.

Les ingénieurs des grandes entreprises partagent souvent leurs impressions sur
les workflows qui durent plus d'une heure. Ils ont des étapes différentes pour
le formatage du code et les tests, la conformité du code et de l'infrastructure,
la construction et les déploiements d'applications, et la connexion avec les
autres intégrations — ont une architecture plus sophistiquée dans l'ensemble. En
même temps, la durée plus longue du pipeline et le taux d'échec entraînent des
coûts plus élevés pour le stockage des applications et du code, par exemple
lorsque les environnements de test ont des travaux de construction séparés qui
fonctionnent de manière autonome, mais si l'un d'eux échoue sur le pipeline,
alors le déploiement s'arrête et la plupart des ressources créées pour ce
workflow génèrent des déchets. Calculer qu'une seule panne sur le système prend
plus d'une heure pour trier le code, le catégoriser pour le tri par
compartiments, puis pour que les ressources humaines le dépannent, trouvent une
solution, et attendent une autre heure pour la prochaine revue.

Un aperçu final, qui n'a pas encore été intégré dans les guides d'organisation
des placards, est celui de la hiérarchie de mémoire multiniveau. Avoir un cache
est efficace, mais avoir plusieurs niveaux de caches — du plus petit et le plus
rapide au plus grand et le plus lent — peut être pour le meilleur ou pour le
pire. Si vous pouvez utiliser le principe LRU comme base pour décider ce qui est
évacué d'un niveau au suivant, vous pourriez également accélérer les choses en
ajoutant encore un niveau de mise en cache.

Si vous commencez par trier vos vêtements, les informaticiens ont révélé une
solution à ce problème aussi. Rik Belew de l'UC San Diego, qui étudie les
moteurs de recherche d'un point de vue cognitif, recommande l'utilisation d'un
valet de chambre. Bien que vous n'en voyiez pas trop ces jours-ci, un valet de
chambre est essentiellement un placard pour une tenue, un cintre composé pour
une veste, une cravate et un pantalon — la pièce d'équipement parfaite pour vos
besoins de mise en cache domestique.

Imaginez que vous ayez un ensemble d'objets en séquence, et que vous devez
périodiquement les rechercher pour trouver des objets spécifiques. La recherche
elle-même est contrainte d'être linéaire — vous devez regarder les objets un par
un, en commençant par le début — mais une fois que vous avez trouvé l'objet que
vous cherchez, vous pouvez le remettre n'importe où dans la séquence. Où
devriez-vous replacer les objets pour rendre la recherche aussi efficace que
possible ?

Intuitivement, puisque la recherche commence à l'avant, vous voulez organiser la
séquence de sorte que les objets recherchés apparaissent là. Mais quels seront
ces objets ? Nous revenons à la clairvoyance encore une fois.

Si vous connaissez la séquence à l'avance, vous pouvez personnaliser la
structure de données pour minimiser le temps total pour l'ensemble de la
séquence. C’est l’algorithme hors ligne optimal, et bien sûr, personne ne
connaît l’avenir, alors comment pouvez-vous vous rapprocher de cet algorithme
optimal ?

Je ne pourrais pas imaginer un meilleur exemple que mon partenaire amoureux
triant les meilleures tenues lors d'une tournée de shopping dans un vaste marché
d'options — il incarne la sélection de vêtements méticuleusement taillés,
personnalisés exclusivement pour l'occasion, pour moi, lui-même et nos amis en
un rien de temps.

Nous, les humains, trions plus que nos données, plus que nos possessions. Nous
nous trions nous-mêmes, et c'est la plus grande tâche herculéenne.

En photo : Kimonos d'Aura Berlin, modèles - Max, Pablo et moi.
