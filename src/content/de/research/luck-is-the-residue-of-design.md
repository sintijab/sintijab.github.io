---
description: "Glück ist das Residuum von Planung"
pubDate: "Sep 10, 2024"
heroImage: "https://images.prismic.io/syntia/Zt-sOhoQrfVKl4OB_my-love.png?auto=format,compress"
author: "Syntia"
categories: "Forschung, Agile Denkweise, Systemdesign, Problemlösung"
subcategories: "Informationsverarbeitung, Informationszugang, Algorithmen, Sortierung, Digitale Kompetenzen"
---

Glück ist das Residuum von Planung und wird von Ursachen bestimmt, die wir in
der Regel selbst steuern können.

Wie bei den Spannungen zwischen Schauen und Springen, Erkunden und Ausnutzen,
ist einer der zentralsten Kompromisse in der Informatik zwischen Sortieren und
Suchen. Das grundlegende Prinzip ist das Sortieren von Materialien als
Vorarbeit, um das spätere Durchsuchen zu erleichtern. Wenn man das Sortieren nur
als Unterstützung für die Zukunft betrachtet, offenbart sich etwas
Überraschendes:

Etwas zu sortieren, das man nie durchsuchen wird, ist eine komplette
Verschwendung; etwas zu durchsuchen, das man nie sortiert hat, ist lediglich
ineffizient.

Zum Beispiel wird bei Suchmaschinen die Informationssortierung vorab
durchgeführt, bevor Ergebnisse verfügbar sind, und die Suche wird von Nutzern
durchgeführt, für die Zeit entscheidend ist. Alle diese Faktoren sprechen für
eine umfangreiche Vorab-Sortierung, wie es bei Suchmaschinen tatsächlich der
Fall ist.

Die Informationsverarbeitung begann in den US-Volkszählungen des neunzehnten
Jahrhunderts mit der Entwicklung von physischen Lochkarten-Sortiergeräten durch
Herman Hollerith und später IBM. 1936 begann IBM mit der Produktion einer Reihe
von Maschinen namens „Collators“, die zwei getrennt geordnete Kartenstapel zu
einem einzigen zusammenführen konnten. Solange beide Stapel sortiert waren, war
das Verfahren, sie zu einem einzigen sortierten Stapel zusammenzuführen,
unglaublich einfach: Man vergleicht einfach die obersten zwei Karten
miteinander, verschiebt die kleinere auf den neuen Stapel, den man erstellt, und
wiederholt den Vorgang, bis man fertig ist.

Tatsächlich war es in vielerlei Hinsicht das Sortieren, das den Computer ins
Leben rief. Die Informatik gibt uns eine Möglichkeit zu verstehen, was hinter
den Kulissen in all diesen Fällen vor sich geht, was uns wiederum Einblicke
geben kann für die Zeiten, in denen wir diejenigen sind, die mit dem
Organisieren von Rechnungen, Papieren, Büchern, Socken und wahrscheinlich öfter
am Tag beschäftigt sind, als uns bewusst ist. Indem sie das Laster (und die
Tugend) der Welt um uns herum quantifiziert, zeigt sie uns auch die Fälle, in
denen es tatsächlich keinen Sinn macht, überhaupt eine Ordnung zu schaffen.

Als Reaktion auf massive wirtschaftliche Turbulenzen entwickelte Präsident
Franklin D. Roosevelt die Idee einer Sozialversicherungsbehörde (SSA), einem
Sicherheitsnetz zur Unterstützung derjenigen, denen finanzieller Schutz fehlt –
ältere Bürger, Menschen mit Behinderungen, Arbeitslose sowie Witwen und Waisen.
Als er im August 1935 die Gesetzgebung unterzeichnete, waren die administrativen
Details kaum vorhanden. Die Herausforderung, mehr als 27 Millionen Einzelkonten
zu erstellen und zu verwalten, stand noch bevor. Es war eine herkulische
Aufgabe. Das System müsste eine massive Menge an Gehaltsdaten sammeln, Zahlungen
berechnen und die Informationen an das US-Finanzministerium übermitteln, das
Schecks für qualifizierte Empfänger ausstellen würde. Die größte
Buchhaltungsaufgabe der Geschichte zu dieser Zeit stand auch unter einem
entmutigenden Zeitplan. Das Gesetz schrieb vor, dass es bis zum 1. Januar 1937
in Kraft sein sollte.

Nicht lange vor all dem, in den frühen Jahren der Depression, machte Thomas J.
Watson Sr., der Präsident von IBM, eine riskante Wette. Aufgrund seiner festen
Überzeugung, dass das SSA-Gesetz letztendlich verabschiedet würde, sah er eine
enorme Geschäftsmöglichkeit für jedes Unternehmen, das den gestiegenen Bedarf an
Datenmanagement in einer erweiterten Regierung decken könnte.

Nachdem der Kongress das Sozialversicherungsprogramm formell genehmigt hatte,
wählte die Regierung IBM aus vielen Bietern aus, kaufte alle Maschinen auf Lager
und bestellte viele weitere. Die IBM 405 Buchhaltungsmaschine und der 077
Collator erwiesen sich zu dieser Zeit als die fortschrittlichsten Rechner, die
erste, die Informationen alphanumerisch verarbeiten konnte, indem sie
spezifische Muster von Einsen und Nullen erkannte und in Buchstaben übersetzte.
Als sie 1934 vorgestellt wurde und 150 Karten pro Minute tabellierte, war die
405 auf dem neuesten Stand der Datenverarbeitung.

Das Programm, das John von Neumann 1945 schrieb, um die Leistungsfähigkeit des
speicherprogrammierten Computers zu demonstrieren, brachte die Idee des
Kollatierens auf die Spitze. Zwei Karten zu sortieren ist einfach: man legt
einfach die kleinere obenauf. Und hat man ein Paar aus zwei sortierten
Kartenstapeln, kann man sie leicht zu einem geordneten Stapel von vier
zusammenführen. Wiederholt man diesen Trick einige Male, baut man größere
Stapel, jeder davon bereits sortiert. Bald genug könnte man sich ein perfekt
sortiertes volles Deck zusammenstellen.

Wenn es Zeit ist, sich zu organisieren, hat man zwei Optionen. Zuerst muss man
entscheiden, was man behalten will, und dann, wie man es anordnet. Die
grundlegende Erkenntnis – dass häufig benötigte Dateien in der Nähe des Ortes
aufbewahrt werden sollten, wo sie verwendet werden – überträgt sich auch auf
rein physische Umgebungen. Beispielsweise verzichten die riesigen
Erfüllungszentren von Amazon im Allgemeinen auf jede Art von
menschenverständlicher Organisation. Ihr Patent besteht darin, Artikel, die in
einer bestimmten Region kürzlich beliebt waren, in ein Zwischenlager in dieser
Region zu schicken – ähnlich wie ein eigenes CDN für physische Güter.

Man sagt uns, unsere Daten seien „in der Cloud“, was einen diffusen, entfernten
Ort suggerieren soll. Wiederum ist nichts davon wahr. Die Realität ist, dass das
Internet alles über Bündel von physischen Kabeln und Reihen von Metallgestellen
geht. Und es ist viel enger mit der Geografie verbunden, als man vielleicht
erwarten würde.

Wenn man einen Cache von Webseiteninhalten erstellen kann, der physisch und
geografisch näher an den Personen liegt, die ihn wollen, kann man diese Seiten
schneller bereitstellen. Ein Großteil des Verkehrs im Internet wird nun von
„Content-Distribution-Netzwerken“ (CDNs) abgewickelt, die über die ganze Welt
verteilt Computer haben, die Kopien beliebter Websites speichern. Dies
ermöglicht es den Nutzern, ihre Daten von einem nahegelegenen Computer
abzurufen, ohne einen langen Weg über Kontinente zum ursprünglichen Server
zurücklegen zu müssen.

Ein Großteil Ihrer Zeit mit einem modernen Browser wird mit dem digitalen
Äquivalent des Papiermischens verbracht. Dieses Mischen wird auch genau auf den
Task-Switching-Schnittstellen von Windows und Mac OS gespiegelt, die Ihre
Anwendungen in der Reihenfolge von der am häufigsten bis zur zuletzt genutzten
auflisten.

Das Caching auf den aktiven Browser-Tabs funktioniert ähnlich. Zuerst, wenn man
entscheidet, was man behalten und was man wegwerfen will, ist das Prinzip des
Zuletzt Genutzten (LRU) am häufigsten. LRU ist das, was Wissenschaftler
„zeitliche Lokalität“ nennen: Wenn ein Programm einmal nach einem bestimmten
Stück Information gefragt hat, wird es dies wahrscheinlich in naher Zukunft
wieder tun. Dies ergibt sich teilweise aus der Art und Weise, wie Computer
Probleme lösen (z. B. durch Ausführen einer Schleife, die schnelle Serien von
Lese- und Schreibvorgängen durchführt), aber es zeigt sich auch in der Art und
Weise, wie Menschen Probleme lösen.

Der direkte Parallelzug zwischen dem Finden des besten Algorithmus, der
vorausschauend handeln und eine optimale Politik ausführen könnte, ist die
„Hellseherei“ – es besteht das Potenzial, die Lösungen für Ihre größten Probleme
bewusst anzuwenden, wenn man die Wissenschaft dahinter anerkennt. Oft gibt es
Fälle, in denen ein System weiß, was zu erwarten ist, wenn man sich so nah wie
intuitiv

möglich heranwagt.

Zum Beispiel lehrt uns LRU, dass das Nächste, was wir erwarten können, das
Letzte ist, was wir benötigen, während das, was wir danach benötigen, das
zweitletzte ist. Gestern habe ich einen Bericht über die Continuous Integration
und Delivery-Metriken erstellt, und während ich nach der Zeit suchte, die
Ingenieure täglich auf das Warten bei jedem Bereitstellungsworkflow verwenden,
stellte ich fest, dass das System, das gut organisiert und umfassend aufgebaut
ist, nicht immer stabil und kosteneffizient ist.

Ingenieure aus großen Unternehmensorganisationen teilen oft ihre Eindrücke über
Workflows, die länger als eine Stunde laufen. Sie haben verschiedene Stufen für
Codeformatierung und -tests, Code- und Infrastrukturkonformität, Anwendungsbau
und -bereitstellungen und Verbindung mit anderen Integrationen – insgesamt eine
ausgefeiltere Architektur. Gleichzeitig führen längere Pipeline-Laufzeiten und
Ausfallraten zu höheren Kosten für die Anwendung und den Code-Speicher, z. B.
wenn die Testumgebungen getrennte Build-Jobs haben, die autonom laufen, aber
wenn einer von ihnen auf der Pipeline fehlschlägt, stoppt die Bereitstellung und
die meisten der für diesen Workflow erstellten Ressourcen generieren Abfall. Es
wurde berechnet, dass ein einzelner Ausfall im System mehr als eine Stunde
dauert, um den Code zu sortieren, ihn für die Bucket-Sortierung zu
kategorisieren und dann für die menschlichen Ressourcen, um das Problem zu
beheben, eine Lösung zu finden und eine weitere Stunde auf die nächste
Überprüfungsrunde zu warten.

Eine letzte Einsicht, die noch nicht in Anleitungen zur Schrankorganisation
eingegangen ist, ist die der mehrstufigen Speicherhierarchie. Einen Cache zu
haben ist effizient, aber mehrere Ebenen von Caches zu haben – von der kleinsten
und schnellsten bis zur größten und langsamsten – kann zum Besseren oder zum
Schlechteren sein. Wenn man das LRU-Prinzip als Grundlage dafür verwenden kann,
was von einer Ebene zur nächsten ausgelagert wird, könnte man die Dinge
beschleunigen, indem man noch eine weitere Ebene des Cachings hinzufügt.

Wenn Sie damit beginnen, Ihre Kleidung zu sortieren, haben Informatiker auch
eine Lösung für dieses Problem gefunden. Rik Belew von der UC San Diego, der
Suchmaschinen aus einer kognitiven Perspektive untersucht, empfahl die
Verwendung eines Bedienerständers. Obwohl man heutzutage nicht mehr viele davon
sieht, ist ein Bedienerständer im Grunde ein Ein-Kleidungsstück-Schrank, ein
Verbundkleiderbügel für Jacke, Krawatte und Hose – das perfekte Stück Hardware
für Ihre häuslichen Caching-Bedürfnisse.

Stellen Sie sich vor, Sie haben eine Reihe von Gegenständen in einer Sequenz,
und Sie müssen periodisch durch sie hindurchsuchen, um bestimmte Gegenstände zu
finden. Die Suche selbst ist auf eine lineare Weise beschränkt – man muss die
Gegenstände nacheinander durchsuchen, beginnend am Anfang – aber sobald man den
gesuchten Gegenstand gefunden hat, kann man ihn irgendwo in der Sequenz
zurücklegen. Wo sollte man die Gegenstände ersetzen, um die Suche so effizient
wie möglich zu gestalten?

Intuitiv, da die Suche am Anfang beginnt, möchten Sie die Sequenz so anordnen,
dass die gesuchten Gegenstände dort erscheinen. Aber welche Gegenstände werden
es sein? Wir sind wieder bei der Hellseherei.

Wenn man die Sequenz im Voraus kennt, kann man die Datenstruktur so anpassen,
dass die Gesamtzeit für die gesamte Sequenz minimiert wird. Das ist der optimale
Offline-Algorithmus, und natürlich kennt niemand die Zukunft, also wie nahe kann
man diesem optimalen Algorithmus kommen?

Ich könnte mir kein besseres Beispiel vorstellen als meinen Lebenspartner, der
die besten Outfits bei einer Shoppingtour aus einem riesigen Markt an Optionen
aussucht – er verkörpert die Auswahl akribisch zugeschnittener, personalisierter
Kleidung, die ausschließlich für Anlässe geeignet ist, für mich, ihn selbst und
unsere Freunde in kürzester Zeit.

Wir Menschen sortieren mehr als unsere Daten, mehr als unsere Besitztümer. Wir
sortieren uns selbst, und das ist die größte herkulische Aufgabe.

Im Foto: Kimonos von Aura Berlin, Modellierung – Max, Pablo und ich.
